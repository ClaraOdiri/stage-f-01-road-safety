{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install --user --upgrade pip\n",
    "\n",
    "#!pip3 install pandas==0.23.4 matplotlib==3.0.3 scipy==1.2.1 scikit-learn==0.22 tensorflow==2.0 keras==1.2.2 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install kubeflow pipeline sdk\n",
    "#!pip3 install kfp --user  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for pipeline\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.components as comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create  directory for outputs.\n",
    "output_dir = \"/home/jovyan/Road-Safety-OSP/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create preprocessing fucntion\n",
    "\n",
    "def preprocess(data_path):\n",
    "    \n",
    "    # Import Libraries\n",
    "    \n",
    "    import pickle\n",
    "    import sys, subprocess;\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install','pandas==0.23.4'])\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # import data\n",
    "    \n",
    "    accident_data = pd.read_csv('https://raw.githubusercontent.com/Uthmanic/07-road-safety/master/data/dftRoadSafety_Accidents_2016.csv')\n",
    "    vehicle_data = pd.read_csv('https://raw.githubusercontent.com/Uthmanic/07-road-safety/master/data/Veh.csv')\n",
    "    \n",
    "    all_data = pd.merge(vehicle_data, accident_data, how = 'inner', on = 'Accident_Index')\n",
    "    \n",
    "    # function for obtaining month in date column\n",
    "    \n",
    "    def month(date):\n",
    "        fulldate = datetime.strptime(date, '%d/%m/%Y')\n",
    "        return int(datetime.strftime(fulldate, '%m'))\n",
    "    \n",
    "    # create a coloumn for month\n",
    "    all_data['Month'] = all_data['Date'].apply(month)\n",
    "    \n",
    "    \n",
    "    # function for obtaining year in date column\n",
    "    def year(date):\n",
    "        fulldate = datetime.strptime(date, '%d/%m/%Y')\n",
    "        return int(datetime.strftime(fulldate, '%Y'))\n",
    "    \n",
    "    # create a coloumn for year\n",
    "    all_data['Year'] = all_data['Date'].apply(year)\n",
    "    \n",
    "     \n",
    "    # function for obtaining hour in time column\n",
    "    def hour(time):\n",
    "        try:\n",
    "            fulltime = datetime.strptime(time, '%H:%M')\n",
    "            return int(datetime.strftime(fulltime, '%H'))\n",
    "        except Exception:\n",
    "            # for missing values \n",
    "            return 0\n",
    "        \n",
    "    # create a coloumn for hour of the day    \n",
    "    all_data['Hour_of_the_day'] = all_data['Time'].apply(hour)\n",
    "    \n",
    "    # drop irrelevant columns\n",
    "    \n",
    "    all_data.drop(['LSOA_of_Accident_Location', 'Local_Authority_(Highway)', 'Time', 'Date'], axis=1, inplace=True)\n",
    "    \n",
    "    # drop rows with nan values \n",
    "    all_data.dropna(inplace=True)\n",
    "\n",
    "    # serialize clean data to output directory\n",
    "    with open(f'{data_path}/clean_data','wb') as f:\n",
    "        pickle.dump((all_data),f)\n",
    "        \n",
    "    \n",
    "    return (print('Done!'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and prediction function\n",
    "\n",
    "def train_predict(data_path):\n",
    "    \n",
    "    # import Library\n",
    "    import pickle\n",
    "    import sys, subprocess;\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install','scikit-learn==0.22'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install','pandas==0.23.4'])\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import  f1_score\n",
    "    \n",
    "    # deserialize clean data from output directory\n",
    "    with open(f'{data_path}/clean_data','rb') as f:\n",
    "        all_data = pickle.load(f)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # create features and targets\n",
    "    X = all_data.drop(columns=['Accident_Index', 'Accident_Severity'])\n",
    "    y = all_data['Accident_Severity']\n",
    "    \n",
    "    # split data based on y categories\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=1)\n",
    "    \n",
    "    # import model\n",
    "    RFC = RandomForestClassifier(random_state=1)\n",
    "\n",
    "    #fit train set\n",
    "    RFC.fit(x_train, y_train)\n",
    "\n",
    "    # predict test set\n",
    "    RFC_pred = RFC.predict(x_test)\n",
    "\n",
    "    # accuracy of test set f1-score\n",
    "    RFC_f1 = f1_score(y_test, RFC_pred,average='micro')\n",
    "    print('RFC f1_score: {}'.format(RFC_f1))\n",
    "    \n",
    "    # write predictions to results.txt\n",
    "    with open(f'{data_path}/results.txt','w') as result:\n",
    "        result.write(f'Prediciton: {RFC_pred} | Actual {y_test}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return(print('Done!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create light weight components\n",
    "\n",
    "preprocess_op = comp.func_to_container_op(preprocess)#, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "train_predict_op = comp.func_to_container_op(train_predict)#, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create client that would enable communication with the Pipelines API server \n",
    "client = kfp.Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_ipython().system('which dsl-compile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "@dsl.pipeline(name=\"Road Safety ML Pipeline\", description=\"Performs Preprocessing, training and prediction\")\n",
    "\n",
    "# Define parameters to be fed into pipeline\n",
    "def road_safety_pipeline(data_path: str ):\n",
    "    \n",
    "    # Define volume to share data between components.\n",
    "    vop = dsl.VolumeOp(\n",
    "    name=\"create_volume\",\n",
    "    resource_name=\"data-volume\", \n",
    "    size=\"1Gi\", \n",
    "    modes=dsl.VOLUME_MODE_RWO) #RWO\n",
    "\n",
    "    # Create preprocess components.\n",
    "    road_safety_preprocess_container = preprocess_op(data_path).add_pvolumes({data_path: vop.volume})\n",
    "\n",
    "    # Create train&prediction component.\n",
    "    road_safety_train_predict_container = train_predict_op(data_path).add_pvolumes({data_path: road_safety_preprocess_container.pvolume})\n",
    "\n",
    "\n",
    "    # Print the result of the prediction\n",
    "    road_safety_result_container = dsl.ContainerOp(\n",
    "            name=\"print_prediction\",\n",
    "            image='library/bash:4.4.23', # 'gcr.io/kubeflow-images-public/tensorflow-2.1.0-notebook-gpu:1.0.0'\n",
    "            pvolumes={data_path: road_safety_train_predict_container.pvolume},\n",
    "            arguments=['cat', f'{data_path}/results.txt']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/jovyan/Road-Safety-OSP/data/clean_data'\n",
    "\n",
    "\n",
    "pipeline_func = road_safety_pipeline\n",
    "\n",
    "experiment_name = 'road_safety_kubeflow'\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "\n",
    "arguments = {\"data_path\":DATA_PATH}\n",
    "\n",
    "# Compile pipeline to generate compressed YAML definition of the pipeline.\n",
    "kfp.compiler.Compiler().compile(pipeline_func,  \n",
    "  '{}.zip'.format(experiment_name))\n",
    "\n",
    "# Submit pipeline directly from pipeline function\n",
    "run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
    "                                                  experiment_name=experiment_name, \n",
    "                                                  run_name=run_name, \n",
    "                                                  arguments=arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
